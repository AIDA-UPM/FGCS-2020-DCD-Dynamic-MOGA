{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reparation techniques\n",
    "This notebook allows reproducing the results of section 4.2 \"Reparation techniques selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working dir\n",
    "import os\n",
    "os.chdir('/home/angel/host_data/')\n",
    "\n",
    "import pymongo\n",
    "\n",
    "# MongoDB\n",
    "from sources.mongo_connection.mongo_connector import MongoDBConnection\n",
    "\n",
    "# Loader\n",
    "from sources.gloaders.dancer_loader import DancerLoader\n",
    "\n",
    "MongoDBConnection.initialize_connection('db', 27017)\n",
    "\n",
    "# load bechmarks names\n",
    "# fixed nodes\n",
    "names = [\n",
    "    \"nodos_fijo_pierde_arista_mas_claro\",\n",
    "    \"nodos_fijo_pierde_arista_mas_difuso\",\n",
    "    \"nodos_fijo_pierde_arista_equilibrio\",\n",
    "    \"nodos_fijo_gana_arista_mas_claro\",\n",
    "    \"nodos_fijo_gana_arista_mas_difuso\",\n",
    "    \"nodos_fijo_gana_arista_equilibrio\",\n",
    "    \"nodos_fijo_mixto_mas_claro\",\n",
    "    \"nodos_fijo_mixto_mas_difuso\",\n",
    "    \"nodos_fijo_mixto_equilibrio\",\n",
    "    \"nodos_fijos_split\",\n",
    "    \"nodos_fijos_merge\",\n",
    "    \"nodos_fijos_split_merge\",\n",
    "    \"nodos_fijos_split_merge__merge_mas\",\n",
    "    \"nodos_fijos_split_merge_split_mas\"\n",
    "]\n",
    "\n",
    "nikcs = [\n",
    "    \"nf_pa_mc\",\n",
    "    \"nf_pa_md\",\n",
    "    \"nf_pa_eq\",\n",
    "    \"nf_ga_mc\",\n",
    "    \"nf_ga_md\",\n",
    "    \"nf_ga_eq\",\n",
    "    \"nf_mx_mc\",\n",
    "    \"nf_mx_md\",\n",
    "    \"nf_mx_eq\",\n",
    "    \"nf_sp\",\n",
    "    \"nf_mg\",\n",
    "    \"nf_sm_eq\",\n",
    "    \"nf_sm_mm\",\n",
    "    \"nf_sm_sm\",\n",
    "]\n",
    "\n",
    "subfixes = [\"_01\", \"_02\", \"_03\"]\n",
    "\n",
    "dataset_nf = []\n",
    "labels_nf = []\n",
    "dataset_names_nf = []\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    for subfix in subfixes:\n",
    "        try:\n",
    "            label = name + subfix\n",
    "    \n",
    "            dataset_names_nf.append(label)    \n",
    "            labels_nf.append(nikcs[i] + subfix)\n",
    "        except Exception as e:\n",
    "            print(\"{0} not available\".format(label))\n",
    "\n",
    "# variable nodes\n",
    "names = [\n",
    "    \"pierde_nodos\",\n",
    "    \"gana_nodos\",\n",
    "    \"mixto\",\n",
    "    \"split\",\n",
    "    \"merge\",\n",
    "    \"split_merge_equilibrio\",\n",
    "    \"split_merge_merge_mas\",\n",
    "    \"split_merge_split_mas\",\n",
    "    \"todo_mixto\"\n",
    "]\n",
    "\n",
    "nikcs = [\n",
    "    \"pd\",\n",
    "    \"gn\",\n",
    "    \"mx\",\n",
    "    \"sp\",\n",
    "    \"mg\",\n",
    "    \"sm_eq\",\n",
    "    \"sm_mm\",\n",
    "    \"sm_sm\",\n",
    "    \"todo\"\n",
    "]\n",
    "\n",
    "subfixes = [\"_01\", \"_02\", \"_03\"]\n",
    "\n",
    "datasets = []\n",
    "labels = []\n",
    "dataset_names = []\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    for subfix in subfixes:\n",
    "        try:\n",
    "            label = name + subfix\n",
    "    \n",
    "            dataset_names.append(label)    \n",
    "            labels.append(nikcs[i] + subfix)\n",
    "        except Exception as e:\n",
    "            print(\"{0} not available\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names_nf:\n",
    "    dancer1 = DancerLoader(dataset_directory=\"data/synthetic_benchmarks/{0}\".format(dataset_name))\n",
    "    try:\n",
    "        dancer1.store_or_update_db(dataset_name)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    dancer1 = DancerLoader(dataset_directory=\"data/synthetic_benchmarks/{0}\".format(dataset_name))\n",
    "    try:\n",
    "        dancer1.store_or_update_db(dataset_name)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graphml_directory': 'data/travian/trevian_market/graphml', 'communities_directory': 'data/travian/trevian_market/communities', 'snapshot_count': 30, 'n_nodes': [1091, 1065, 1028, 1013, 1067, 1079, 1090, 1026, 1039, 1042, 974, 965, 1006, 1040, 1002, 981, 1007, 958, 909, 870, 853, 877, 876, 821, 847, 805, 846, 850, 817, 796], 'n_edges': [2478, 2305, 2258, 2263, 2460, 2551, 2598, 2351, 2408, 2440, 2430, 2401, 2491, 2506, 2475, 2542, 2464, 2364, 2272, 2084, 2091, 2191, 2024, 1949, 1947, 2055, 2178, 2115, 2054, 1985], 'ground_truth': True, 'n_communites': [107, 96, 92, 93, 93, 92, 94, 85, 85, 81, 78, 79, 81, 81, 88, 78, 83, 79, 72, 70, 74, 74, 70, 75, 81, 83, 79, 81, 73, 74]}\n",
      "{'graphml_directory': 'data/travian/trevian_messages/graphml', 'communities_directory': 'data/travian/trevian_messages/communities', 'snapshot_count': 30, 'n_nodes': [1789, 1931, 1711, 1717, 1657, 1730, 1836, 1750, 1771, 1560, 1641, 1681, 1647, 1564, 1604, 1649, 1475, 1617, 1568, 1401, 1461, 1495, 1527, 1492, 1439, 1233, 1384, 1368, 1275, 1378], 'n_edges': [4697, 4420, 4204, 3892, 4084, 4034, 4218, 4059, 4707, 3776, 3616, 4360, 3926, 3623, 3905, 4320, 3269, 4289, 3831, 3243, 3515, 3869, 3732, 3472, 2710, 2346, 2618, 2688, 2214, 2499], 'ground_truth': True, 'n_communites': [93, 96, 96, 87, 85, 88, 93, 83, 88, 83, 87, 85, 90, 83, 82, 74, 74, 85, 81, 70, 76, 75, 71, 80, 87, 72, 70, 69, 72, 71]}\n"
     ]
    }
   ],
   "source": [
    "from sources.gloaders.trevian_loader import TrevianLoader\n",
    "\n",
    "# market\n",
    "dataset_name = \"travian_market\"\n",
    "dataset = TrevianLoader(graphml_directory=\"data/travian/trevian_market/graphml\",\n",
    "                        communities_directory=\"data/travian/trevian_market/communities\")\n",
    "dataset.store_or_update_db(dataset_name)\n",
    "dataset.summary()\n",
    "\n",
    "# messages\n",
    "dataset_name = \"travian_messages\"\n",
    "dataset = TrevianLoader(graphml_directory=\"data/travian/trevian_messages/graphml\",\n",
    "                        communities_directory=\"data/travian/trevian_messages/communities\")\n",
    "dataset.store_or_update_db(dataset_name)\n",
    "dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.gas.dynamic_ga_configuration import DynamicGaConfiguration\n",
    "from sources.gas.dynamic_ga_immigrants_config import DynamicGaImmigrantsConfiguration as DCDImmigrantsGAConfig\n",
    "from sources.gas.dcd_gas_immigrants_combine_reparators_config import DCDGasImmigrantsCombineReparatorsConfig\n",
    "from sources.gas.nsga2_config import NSGAIIConfig\n",
    "\n",
    "from sources.reparators.greedy_reparator import GreedyReparator\n",
    "from sources.reparators.walk_reparator import RandomWalkReparator\n",
    "\n",
    "# Standard\n",
    "d_config = DynamicGaConfiguration(NSGAIIConfig())\n",
    "d_config.store_or_update_db(\"standard\")\n",
    "\n",
    "# Label Propagation\n",
    "ga_configs = NSGAIIConfig()\n",
    "reparator = GreedyReparator(\"greedy\")\n",
    "\n",
    "rates = 0.0\n",
    "d_config = DCDImmigrantsGAConfig(ga_configs, rates, reparator)\n",
    "d_config.store_or_update_db(\"label_propagation\")\n",
    "\n",
    "# Random walks\n",
    "ga_configs = NSGAIIConfig()\n",
    "reparator = RandomWalkReparator(\"rw\", 5, 6)\n",
    "\n",
    "rates = 0.0\n",
    "d_config = DCDImmigrantsGAConfig(ga_configs, rates, reparator)\n",
    "d_config.store_or_update_db(\"random_walks\")\n",
    "\n",
    "# Hybrid\n",
    "ga_configs = NSGAIIConfig()\n",
    "r1 = RandomWalkReparator(\"rw\", 5, 6)\n",
    "r2 = GreedyReparator(\"greedy\")\n",
    "\n",
    "rates = 0.0\n",
    "d_config = DCDGasImmigrantsCombineReparatorsConfig(ga_configs, rates, r1, r2)\n",
    "d_config.store_or_update_db(\"greedy_random_walks_combine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "import sources.experiment.experiment_execution as executor\n",
    "\n",
    "for dataset_name in dataset_names_nf:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"standard\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))\n",
    "    \n",
    "for dataset_name in dataset_names:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"standard\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label propagation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "import sources.experiment.experiment_execution as executor\n",
    "\n",
    "for dataset_name in dataset_names_nf:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"label_propagation\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))\n",
    "    \n",
    "for dataset_name in dataset_names:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"label_propagation\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random walks method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "import sources.experiment.experiment_execution as executor\n",
    "\n",
    "# synthetic\n",
    "for dataset_name in dataset_names_nf:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"random_walks\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))\n",
    "    \n",
    "for dataset_name in dataset_names:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"random_walks\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))\n",
    "        \n",
    "# real\n",
    "executor.add_iterations_if_needed(\"travian_market\", \"random_walks\", 20)\n",
    "executor.add_iterations_if_needed(\"travian_messages\", \"random_walks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "import sources.experiment.experiment_execution as executor\n",
    "\n",
    "for dataset_name in dataset_names_nf:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"greedy_random_walks_combine\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))\n",
    "    \n",
    "for dataset_name in dataset_names:\n",
    "    try:\n",
    "        print(dataset_name)\n",
    "        executor.add_iterations_if_needed(dataset_name, \"greedy_random_walks_combine\", 20)\n",
    "    except Exception as e:\n",
    "        print(\"Error in dataset {0}: {1}\".format(dataset_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_tables import save_max_sum_hv_table_csv, save_max_sum_hv_kruskall_hypothesis_table_csv\n",
    "\n",
    "settings_list_nf = [\"label_propagation\", \"random_walks\", \"greedy_random_walks_combine\"]\n",
    "settings_nick_nf = [\"label propagation\", \"Random Walks\", \"Hybrid\"]\n",
    "\n",
    "exp_matrix_nf = []\n",
    "for settings in settings_list_nf:\n",
    "    exp_list = []\n",
    "    \n",
    "    for dataset in dataset_names_nf:\n",
    "        exp_list.append(ExperimentLoader(dataset, settings))\n",
    "    exp_matrix_nf.append(exp_list)\n",
    "    \n",
    "save_max_sum_hv_table_csv(\"tables/table_3_mean_std.csv\", exp_matrix_nf, settings_nick_nf, labels_nf)\n",
    "save_max_sum_hv_kruskall_hypothesis_table_csv(\"tables/table_3_kruskall.csv\", exp_matrix_nf, settings_nick_nf, labels_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_tables import save_max_sum_hv_table_csv, save_max_sum_hv_kruskall_hypothesis_table_csv\n",
    "\n",
    "settings_list = [\"label_propagation\", \"random_walks\", \"greedy_random_walks_combine\"]\n",
    "settings_nick = [\"label propagation\", \"Random Walks\", \"Hybrid\"]\n",
    "\n",
    "exp_matrix = []\n",
    "for settings in settings_list:\n",
    "    exp_list = []\n",
    "    \n",
    "    for dataset in dataset_names:\n",
    "        exp_list.append(ExperimentLoader(dataset, settings))\n",
    "    exp_matrix.append(exp_list)\n",
    "    \n",
    "save_max_sum_hv_table_csv(\"tables/table_4_mean_std.csv\", exp_matrix, settings_nick, labels)\n",
    "save_max_sum_hv_kruskall_hypothesis_table_csv(\"tables/table_4_kruskall.csv\", exp_matrix, settings_nick, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables 5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_tables import save_avg_sqr_error_table_csv, save_avg_sqr_error_kruskall_hypothesis_table_csv\n",
    "\n",
    "lbs = [\"nf_mx_eq_01\", \"nf_mx_eq_02\", \"nf_mx_eq_03\",\n",
    "       \"nf_sm_eq_01\", \"nf_sm_eq_02\", \"nf_sm_eq_03\",\n",
    "       \"mx_01\", \"mx_02\", \"mx_03\",\n",
    "       \"sm_eq_01\", \"sm_eq_02\", \"sm_eq_03\"\n",
    "        ]\n",
    "d_names = [\n",
    "    dataset_names_nf[labels_nf.index(lbs[0])], dataset_names_nf[labels_nf.index(lbs[1])], dataset_names_nf[labels_nf.index(lbs[2])],\n",
    "    dataset_names_nf[labels_nf.index(lbs[3])], dataset_names_nf[labels_nf.index(lbs[4])], dataset_names_nf[labels_nf.index(lbs[5])],\n",
    "    dataset_names[labels.index(lbs[6])], dataset_names[labels.index(lbs[7])], dataset_names[labels.index(lbs[8])],\n",
    "    dataset_names[labels.index(lbs[9])], dataset_names[labels.index(lbs[10])], dataset_names[labels.index(lbs[11])]\n",
    "]\n",
    "\n",
    "settings_list = [\"standard\", \"random_walks\"]\n",
    "settings_nick = [\"Standard\", \"Immigrant's\"]\n",
    "\n",
    "exp_matrix = []\n",
    "for settings in settings_list:\n",
    "    exp_list = []\n",
    "    \n",
    "    for dataset in d_names:\n",
    "        exp_list.append(ExperimentLoader(dataset, settings))\n",
    "    exp_matrix.append(exp_list)\n",
    "\n",
    "save_avg_sqr_error_table_csv(\"tables/table_5-6_mean_std.csv\", exp_matrix, settings_nick, lbs)\n",
    "save_avg_sqr_error_kruskall_hypothesis_table_csv(\"tables/table_5_kruskall.csv\", exp_matrix, settings_nick, lbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_tables import save_mni_table_csv\n",
    "\n",
    "save_mni_table_csv(\"tables/table_7_mean_std.csv\", [ExperimentLoader(\"travian_messages\", \"random_walks\")], [\"Immigrant's\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_tables import save_mni_table_csv\n",
    "\n",
    "save_mni_table_csv(\"tables/table_8_mean_std.csv\", [ExperimentLoader(\"travian_market\", \"random_walks\")], [\"Immigrant's\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.experiment.experiment_loader import ExperimentLoader\n",
    "from sources.experiment.experiment_plotting import compare_times_taken, generations_total_comparison\n",
    "\n",
    "lbs = [\"nf_mx_eq_01\", \"nf_mx_eq_02\", \"nf_mx_eq_03\",\n",
    "       \"nf_sm_eq_01\", \"nf_sm_eq_02\", \"nf_sm_eq_03\",\n",
    "       \"mx_01\", \"mx_02\", \"mx_03\",\n",
    "       \"sm_eq_01\", \"sm_eq_02\", \"sm_eq_03\"\n",
    "        ]\n",
    "d_names = [\n",
    "    dataset_names_nf[labels_nf.index(lbs[0])], dataset_names_nf[labels_nf.index(lbs[1])], dataset_names_nf[labels_nf.index(lbs[2])],\n",
    "    dataset_names_nf[labels_nf.index(lbs[3])], dataset_names_nf[labels_nf.index(lbs[4])], dataset_names_nf[labels_nf.index(lbs[5])],\n",
    "    dataset_names[labels.index(lbs[6])], dataset_names[labels.index(lbs[7])], dataset_names[labels.index(lbs[8])],\n",
    "    dataset_names[labels.index(lbs[9])], dataset_names[labels.index(lbs[10])], dataset_names[labels.index(lbs[11])]\n",
    "]\n",
    "\n",
    "settings_list = [\"standard\", \"random_walks\"]\n",
    "settings_nick = [\"Standard\", \"Immigrant's\"]\n",
    "\n",
    "exp_matrix = []\n",
    "for settings in settings_list:\n",
    "    exp_list = []\n",
    "    \n",
    "    for dataset in d_names:\n",
    "        exp_list.append(ExperimentLoader(dataset, settings))\n",
    "    exp_matrix.append(exp_list)\n",
    "    \n",
    "compare_times_taken(\"figures/figure_9_b.png\", exp_matrix, settings_nick, lbs,\n",
    "                   yticks=[0, 5*60, 10*60, 15*60, 20*60, 25*60, 30*60],\n",
    "                   ylabels=[\"0 minutes\", \"5 minutes\", \"10minutes\", \"15minutes\", \"20minutes\", \"25minutes\", \"30minutes\"])\n",
    "generations_total_comparison(\"figures/figure_9_a.png\", exp_matrix, settings_nick, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
